{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-tkIHednLFu",
        "outputId": "623c6df9-2f57-4fc6-ee90-2a7f50f7973c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enhanced LSTM Model for Music Generation\n",
        "Building upon the foundations of recurrent neural networks, this model leverages the power of bidirectional LSTMs and regularization techniques to create a more robust and capable system for music generation tasks.\n",
        "\n",
        "## Enhanced Sampling for Generation\n",
        "Implementing Temperature Sampling will allow control of the randomness of predictions. A higher temperature results in more random outputs, and a lower temperature makes the model's outputs more deterministic.\n"
      ],
      "metadata": {
        "id": "7QyVpT5v-rGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "s7OiSdrmRt4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-ATcHWKkMve"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from music21 import converter, instrument, note, chord\n",
        "\n",
        "def read_midi(file):\n",
        "    print(\"Loading Music File:\", file)\n",
        "    notes = []\n",
        "\n",
        "    midi = converter.parse(file)\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    relevant_parts = parts.parts if parts else [midi]\n",
        "\n",
        "    for part in relevant_parts:\n",
        "        if 'Violin' in str(part.getInstrument()) or 'Violin' in str(part.partName):\n",
        "            for element in part.recurse():\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append((str(element.pitch), element.duration.quarterLength, element.offset))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append(('.'.join(str(n) for n in element.normalOrder), element.duration.quarterLength, element.offset))\n",
        "                elif isinstance(element, note.Rest):\n",
        "                    notes.append(('rest', element.duration.quarterLength, element.offset))\n",
        "\n",
        "    return notes\n",
        "\n",
        "\n",
        "path = '/content/gdrive/MyDrive/Violin_Comp_Data/all_midi_files/'\n",
        "files = [i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
        "notes_array = [read_midi(os.path.join(path, file)) for file in files]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding each unique note to an integer."
      ],
      "metadata": {
        "id": "kFSRzbE2WuO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten\n",
        "all_notes = [note for sequence in notes_array for note in sequence]"
      ],
      "metadata": {
        "id": "9Lh5q_CQN4p-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fractions import Fraction\n",
        "\n",
        "all_notes = [(pitch, float(duration) if isinstance(duration, Fraction) else duration,\n",
        "              float(offset) if isinstance(offset, Fraction) else offset)\n",
        "             for pitch, duration, offset in all_notes]\n"
      ],
      "metadata": {
        "id": "c_i1YG2BOOmn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notes_array = [[(pitch, float(duration) if isinstance(duration, Fraction) else duration,\n",
        "                 float(offset) if isinstance(offset, Fraction) else offset)\n",
        "                for pitch, duration, offset in sequence]\n",
        "               for sequence in notes_array]\n"
      ],
      "metadata": {
        "id": "YLBsO1HBORKn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "note_to_int = {note: i for i, note in enumerate(sorted(set(all_notes)))}\n"
      ],
      "metadata": {
        "id": "3n7HKWl1OT10"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "output_notes = []\n",
        "no_of_timesteps = 100\n",
        "\n",
        "for notes in notes_array:\n",
        "    for i in range(len(notes) - no_of_timesteps):\n",
        "        input_seq = notes[i:i + no_of_timesteps]\n",
        "        output_note = notes[i + no_of_timesteps]\n",
        "        input_sequences.append([note_to_int[note] for note in input_seq])\n",
        "        output_notes.append(note_to_int[output_note])\n",
        "\n",
        "x_seq = np.array(input_sequences)\n",
        "y_seq = np.array(output_notes)\n"
      ],
      "metadata": {
        "id": "30rW9Qf7OWIv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initiating Train-Test Split & Reshaping Input for LSTM Model"
      ],
      "metadata": {
        "id": "-FNWACczUx9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq, y_seq, test_size=0.2, random_state=13)\n",
        "x_tr = np.reshape(x_tr, (x_tr.shape[0], no_of_timesteps, 1))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], no_of_timesteps, 1))\n"
      ],
      "metadata": {
        "id": "rORuqgonXcTj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting LSTM Model Complexity"
      ],
      "metadata": {
        "id": "OohVKtacSrIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Model Configuration\n",
        "no_of_timesteps = 100\n",
        "num_notes = len(note_to_int)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First Bidirectional LSTM Layer\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True, kernel_regularizer=l2(0.001)), input_shape=(no_of_timesteps, 1)))\n",
        "\n",
        "# Second LSTM Layer\n",
        "model.add(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.001)))\n",
        "\n",
        "# Third Bidirectional LSTM Layer\n",
        "model.add(Bidirectional(LSTM(64, kernel_regularizer=l2(0.001))))\n",
        "\n",
        "# Dense Layer with Regularization\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(num_notes, activation='softmax'))\n",
        "\n",
        "# Optimizer Configuration\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa49DYYvmYQe",
        "outputId": "01968a30-c7dc-4277-8fc6-2001a0e24ff4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirection  (None, 100, 512)          528384    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 128)          328192    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 128)               98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4915)              634035    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1605939 (6.13 MB)\n",
            "Trainable params: 1605939 (6.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Checkpoint"
      ],
      "metadata": {
        "id": "sQ75RPLZ_Mih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "mc = ModelCheckpoint('best_model_lstm2.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)"
      ],
      "metadata": {
        "id": "sBjqEA7WmYOU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "LFg8TNpb_O0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_tr, y_tr, epochs=50, batch_size=64, validation_data=(x_val, y_val), callbacks=[mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRl6w_DFmYMi",
        "outputId": "584d2071-d37d-4527-aa94-31ab68f172b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 9.4701 - accuracy: 0.0000e+00\n",
            "Epoch 1: val_loss improved from inf to 9.43121, saving model to best_model_violin.h5\n",
            "3/3 [==============================] - 19s 2s/step - loss: 9.4701 - accuracy: 0.0000e+00 - val_loss: 9.4312 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - ETA: 0s - loss: 9.3349 - accuracy: 0.0000e+00\n",
            "Epoch 2: val_loss improved from 9.43121 to 9.38160, saving model to best_model_violin.h5\n",
            "3/3 [==============================] - 5s 2s/step - loss: 9.3349 - accuracy: 0.0000e+00 - val_loss: 9.3816 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 9.1320 - accuracy: 0.0224\n",
            "Epoch 3: val_loss improved from 9.38160 to 9.34674, saving model to best_model_violin.h5\n",
            "3/3 [==============================] - 5s 2s/step - loss: 9.1320 - accuracy: 0.0224 - val_loss: 9.3467 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 8.8084 - accuracy: 0.0075\n",
            "Epoch 4: val_loss improved from 9.34674 to 9.33394, saving model to best_model_violin.h5\n",
            "3/3 [==============================] - 4s 1s/step - loss: 8.8084 - accuracy: 0.0075 - val_loss: 9.3339 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 8.3328 - accuracy: 0.0075\n",
            "Epoch 5: val_loss did not improve from 9.33394\n",
            "3/3 [==============================] - 4s 1s/step - loss: 8.3328 - accuracy: 0.0075 - val_loss: 9.3610 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 7.6616 - accuracy: 0.0075\n",
            "Epoch 6: val_loss did not improve from 9.33394\n",
            "3/3 [==============================] - 5s 2s/step - loss: 7.6616 - accuracy: 0.0075 - val_loss: 9.5078 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 6.7469 - accuracy: 0.0149\n",
            "Epoch 7: val_loss did not improve from 9.33394\n",
            "3/3 [==============================] - 5s 1s/step - loss: 6.7469 - accuracy: 0.0149 - val_loss: 10.0200 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 6.0895 - accuracy: 0.0075\n",
            "Epoch 8: val_loss did not improve from 9.33394\n",
            "3/3 [==============================] - 4s 1s/step - loss: 6.0895 - accuracy: 0.0075 - val_loss: 11.1348 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.6674 - accuracy: 0.0224\n",
            "Epoch 9: val_loss did not improve from 9.33394\n",
            "3/3 [==============================] - 4s 1s/step - loss: 5.6674 - accuracy: 0.0224 - val_loss: 12.4505 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.5410 - accuracy: 0.0000e+00\n",
            "Epoch 10: val_loss did not improve from 9.33394\n",
            "3/3 [==============================] - 6s 2s/step - loss: 5.5410 - accuracy: 0.0000e+00 - val_loss: 13.5584 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Best Model"
      ],
      "metadata": {
        "id": "8SqKZxRr_SoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('best_model_lstm2.h5')"
      ],
      "metadata": {
        "id": "ltnjLjqfmYIo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temperature Sampling"
      ],
      "metadata": {
        "id": "h58WC1Uw8gj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_with_temperature(probabilities, temperature=1.0):\n",
        "    if temperature <= 0:\n",
        "        return np.argmax(probabilities)\n",
        "    else:\n",
        "        probabilities = np.asarray(probabilities).astype('float64')\n",
        "        probabilities = np.log(probabilities + 1e-7) / temperature\n",
        "        exp_probs = np.exp(probabilities)\n",
        "        probabilities = exp_probs / np.sum(exp_probs)\n",
        "        return np.random.choice(range(len(probabilities)), p=probabilities)\n"
      ],
      "metadata": {
        "id": "9zS5Kuz68YdB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_music(model, start_sequence, length=50, temperature=.96, lookback_length=100):\n",
        "    prediction_output = []\n",
        "\n",
        "    # Ensuring start_sequence is of length lookback_length\n",
        "    if len(start_sequence) > lookback_length:\n",
        "        start_sequence = start_sequence[-lookback_length:]\n",
        "    elif len(start_sequence) < lookback_length:\n",
        "        # Pad the sequence if it's too short\n",
        "        start_sequence = [('rest', 0, 0)] * (lookback_length - len(start_sequence)) + start_sequence\n",
        "\n",
        "    start_sequence_formatted = np.array([note_to_int[note] for note in start_sequence])\n",
        "\n",
        "    for note_index in range(length):\n",
        "        prediction_input = np.reshape(start_sequence_formatted, (1, lookback_length, 1))\n",
        "        prob = model.predict(prediction_input)[0]\n",
        "        index = sample_with_temperature(prob, temperature)\n",
        "        predicted_note = x_int_to_note[index]\n",
        "        prediction_output.append(predicted_note)\n",
        "\n",
        "        # Update start_sequence_formatted for the next prediction\n",
        "        start_sequence_formatted = np.append(start_sequence_formatted, [index])[-lookback_length:]\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "\n",
        "# Create the inverse mapping from integers back to note tuples\n",
        "x_int_to_note = dict((number, note) for note, number in note_to_int.items())\n"
      ],
      "metadata": {
        "id": "wF87tLOZmYGg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The convert_to_midi function assumes that each note_info in prediction_output is a tuple with the structure (note, duration, offset), where:\n",
        "\n",
        "- **note** can be either a note name (like 'C#4') or 'rest'.\n",
        "- **duration** is the note's duration in quarterLength.\n",
        "- **offset** is the note's offset."
      ],
      "metadata": {
        "id": "ltfz0QJu9yuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import pitch\n",
        "\n",
        "def midi_number_to_note_name(midi_number):\n",
        "    return pitch.Pitch(midi=midi_number).nameWithOctave\n"
      ],
      "metadata": {
        "id": "MqB3wXP-QQ5z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import stream, instrument, note, chord\n",
        "\n",
        "def convert_to_midi(prediction_output):\n",
        "    midi_stream = stream.Stream()\n",
        "    midi_stream.append(instrument.Violin())\n",
        "\n",
        "    offset = 0\n",
        "    for i, note_info in enumerate(prediction_output):\n",
        "        try:\n",
        "            note_name = note_info[0]\n",
        "            # Check if note_name is a MIDI number and convert it\n",
        "            if note_name.isdigit():\n",
        "                note_name = midi_number_to_note_name(int(note_name))\n",
        "\n",
        "            # Create note or rest\n",
        "            if note_name != 'rest':\n",
        "                new_note = note.Note(note_name)\n",
        "            else:\n",
        "                new_note = note.Rest()\n",
        "\n",
        "            new_note.duration.quarterLength = note_info[1]\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Violin()\n",
        "            midi_stream.append(new_note)\n",
        "            offset += new_note.duration.quarterLength\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing note at position {i}: {note_info}. Error: {e}\")\n",
        "\n",
        "    midi_stream.write('midi', fp='lstm_music2.mid')\n",
        "\n",
        "# Randomly select a starting sequence from x_val\n",
        "random_index = np.random.randint(0, len(x_val))\n",
        "start_sequence = x_val[random_index]\n",
        "\n",
        "# Since start_sequence is currently encoded as integers, decode it back to note information\n",
        "start_sequence_decoded = [x_int_to_note[note] for note in start_sequence.flatten()]\n",
        "\n",
        "# Generate music based on the starting sequence\n",
        "prediction_output = generate_music(model, start_sequence_decoded)\n",
        "convert_to_midi(prediction_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUEJ-01RQW0M",
        "outputId": "04a0d4db-20e1-4bcb-df6c-92446460d3fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 161ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 160ms/step\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ft02X1S3nfLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}