{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-tkIHednLFu",
        "outputId": "16bb4496-8eb9-41af-eb4a-1a1dfaff7173"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation\n",
        "Adjusting note representation to include note duration and time offsets."
      ],
      "metadata": {
        "id": "s7OiSdrmRt4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-ATcHWKkMve"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from music21 import converter, instrument, note, chord\n",
        "\n",
        "def read_midi(file):\n",
        "    print(\"Loading Music File:\", file)\n",
        "    notes = []\n",
        "\n",
        "    midi = converter.parse(file)\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    relevant_parts = parts.parts if parts else [midi]\n",
        "\n",
        "    for part in relevant_parts:\n",
        "        if 'Violin' in str(part.getInstrument()) or 'Violin' in str(part.partName):\n",
        "            for element in part.recurse():\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append((str(element.pitch), element.duration.quarterLength, element.offset))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append(('.'.join(str(n) for n in element.normalOrder), element.duration.quarterLength, element.offset))\n",
        "                elif isinstance(element, note.Rest):\n",
        "                    notes.append(('rest', element.duration.quarterLength, element.offset))\n",
        "\n",
        "    return notes\n",
        "\n",
        "\n",
        "path = '/content/gdrive/MyDrive/Violin_Comp_Data/all_midi_files/'\n",
        "files = [i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
        "notes_array = [read_midi(os.path.join(path, file)) for file in files]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding each unique note to an integer"
      ],
      "metadata": {
        "id": "kFSRzbE2WuO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten\n",
        "all_notes = [note for sequence in notes_array for note in sequence]\n",
        "\n",
        "# Mapping from notes to integers\n",
        "note_to_int = {note: i for i, note in enumerate(sorted(set(all_notes)))}\n",
        "\n",
        "# Encode sequences\n",
        "input_sequences = []\n",
        "output_notes = []\n",
        "no_of_timesteps = 32\n",
        "\n",
        "for notes in notes_array:\n",
        "    for i in range(len(notes) - no_of_timesteps):\n",
        "        input_seq = notes[i:i + no_of_timesteps]\n",
        "        output_note = notes[i + no_of_timesteps]\n",
        "        input_sequences.append([note_to_int[note] for note in input_seq])\n",
        "        output_notes.append(note_to_int[output_note])\n",
        "\n",
        "x_seq = np.array(input_sequences)\n",
        "y_seq = np.array(output_notes)\n"
      ],
      "metadata": {
        "id": "z3yOeDPRbIxy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initiating Train-Test Split & Reshaping Input for LSTM Model"
      ],
      "metadata": {
        "id": "-FNWACczUx9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq, y_seq, test_size=0.2, random_state=13)\n",
        "x_tr = np.reshape(x_tr, (x_tr.shape[0], no_of_timesteps, 1))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], no_of_timesteps, 1))\n"
      ],
      "metadata": {
        "id": "rORuqgonXcTj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM Model Architecture\n",
        "Trying a LSTM-based architecture for better sequence generation."
      ],
      "metadata": {
        "id": "OohVKtacSrIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(no_of_timesteps, 1), return_sequences=True))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(note_to_int), activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa49DYYvmYQe",
        "outputId": "03ba7cea-7929-40ae-da7e-dae0a8b30251"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 32, 256)           264192    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4915)              1263155   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2118451 (8.08 MB)\n",
            "Trainable params: 2118451 (8.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Checkpoint"
      ],
      "metadata": {
        "id": "lffS56B88E7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "mc = ModelCheckpoint('best_model_lstm1.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)"
      ],
      "metadata": {
        "id": "sBjqEA7WmYOU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "gFMZPsfo8CIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_tr, y_tr, epochs=50, batch_size=128, validation_data=(x_val, y_val), callbacks=[mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRl6w_DFmYMi",
        "outputId": "92af064c-8635-4366-92bb-643a15814bab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 8.5146 - accuracy: 6.1425e-04\n",
            "Epoch 1: val_loss improved from inf to 8.51159, saving model to best_model_violin.h5\n",
            "13/13 [==============================] - 14s 772ms/step - loss: 8.5146 - accuracy: 6.1425e-04 - val_loss: 8.5116 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - ETA: 0s - loss: 8.1360 - accuracy: 0.0043\n",
            "Epoch 2: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 513ms/step - loss: 8.1360 - accuracy: 0.0043 - val_loss: 9.5193 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.6154 - accuracy: 0.0037\n",
            "Epoch 3: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 688ms/step - loss: 7.6154 - accuracy: 0.0037 - val_loss: 9.8468 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.4340 - accuracy: 0.0037\n",
            "Epoch 4: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 514ms/step - loss: 7.4340 - accuracy: 0.0037 - val_loss: 10.4366 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.3774 - accuracy: 0.0049\n",
            "Epoch 5: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 693ms/step - loss: 7.3774 - accuracy: 0.0049 - val_loss: 10.9787 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.3528 - accuracy: 0.0025\n",
            "Epoch 6: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 517ms/step - loss: 7.3528 - accuracy: 0.0025 - val_loss: 10.8116 - val_accuracy: 0.0025\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.3157 - accuracy: 0.0025\n",
            "Epoch 7: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 694ms/step - loss: 7.3157 - accuracy: 0.0025 - val_loss: 11.0647 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.2885 - accuracy: 0.0049\n",
            "Epoch 8: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 517ms/step - loss: 7.2885 - accuracy: 0.0049 - val_loss: 11.1906 - val_accuracy: 0.0025\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.2186 - accuracy: 0.0025\n",
            "Epoch 9: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 690ms/step - loss: 7.2186 - accuracy: 0.0025 - val_loss: 11.2795 - val_accuracy: 0.0025\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 7.0962 - accuracy: 0.0043\n",
            "Epoch 10: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 518ms/step - loss: 7.0962 - accuracy: 0.0043 - val_loss: 11.5958 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.9696 - accuracy: 0.0037\n",
            "Epoch 11: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 693ms/step - loss: 6.9696 - accuracy: 0.0037 - val_loss: 11.8425 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.8437 - accuracy: 0.0031\n",
            "Epoch 12: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 512ms/step - loss: 6.8437 - accuracy: 0.0031 - val_loss: 12.2141 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.7232 - accuracy: 0.0049\n",
            "Epoch 13: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 695ms/step - loss: 6.7232 - accuracy: 0.0049 - val_loss: 12.3293 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.5981 - accuracy: 0.0061\n",
            "Epoch 14: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 523ms/step - loss: 6.5981 - accuracy: 0.0061 - val_loss: 12.6898 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.4947 - accuracy: 0.0061\n",
            "Epoch 15: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 692ms/step - loss: 6.4947 - accuracy: 0.0061 - val_loss: 12.8657 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.3452 - accuracy: 0.0104\n",
            "Epoch 16: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 521ms/step - loss: 6.3452 - accuracy: 0.0104 - val_loss: 13.0474 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.2154 - accuracy: 0.0061\n",
            "Epoch 17: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 697ms/step - loss: 6.2154 - accuracy: 0.0061 - val_loss: 13.3660 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 6.1030 - accuracy: 0.0068\n",
            "Epoch 18: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 518ms/step - loss: 6.1030 - accuracy: 0.0068 - val_loss: 13.4990 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.9698 - accuracy: 0.0129\n",
            "Epoch 19: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 691ms/step - loss: 5.9698 - accuracy: 0.0129 - val_loss: 13.7561 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.8168 - accuracy: 0.0104\n",
            "Epoch 20: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 523ms/step - loss: 5.8168 - accuracy: 0.0104 - val_loss: 14.2003 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.7158 - accuracy: 0.0111\n",
            "Epoch 21: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 10s 770ms/step - loss: 5.7158 - accuracy: 0.0111 - val_loss: 14.4698 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.5912 - accuracy: 0.0160\n",
            "Epoch 22: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 514ms/step - loss: 5.5912 - accuracy: 0.0160 - val_loss: 14.3718 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.4687 - accuracy: 0.0215\n",
            "Epoch 23: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 696ms/step - loss: 5.4687 - accuracy: 0.0215 - val_loss: 14.6772 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.3311 - accuracy: 0.0301\n",
            "Epoch 24: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 514ms/step - loss: 5.3311 - accuracy: 0.0301 - val_loss: 14.9754 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.1772 - accuracy: 0.0369\n",
            "Epoch 25: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 693ms/step - loss: 5.1772 - accuracy: 0.0369 - val_loss: 15.3251 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 5.0834 - accuracy: 0.0338\n",
            "Epoch 26: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 511ms/step - loss: 5.0834 - accuracy: 0.0338 - val_loss: 15.3743 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.9166 - accuracy: 0.0430\n",
            "Epoch 27: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 692ms/step - loss: 4.9166 - accuracy: 0.0430 - val_loss: 15.7573 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.8193 - accuracy: 0.0399\n",
            "Epoch 28: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 516ms/step - loss: 4.8193 - accuracy: 0.0399 - val_loss: 15.9657 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.7306 - accuracy: 0.0528\n",
            "Epoch 29: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 696ms/step - loss: 4.7306 - accuracy: 0.0528 - val_loss: 16.0637 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.6034 - accuracy: 0.0602\n",
            "Epoch 30: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 515ms/step - loss: 4.6034 - accuracy: 0.0602 - val_loss: 16.0825 - val_accuracy: 0.0049\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.4609 - accuracy: 0.0700\n",
            "Epoch 31: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 691ms/step - loss: 4.4609 - accuracy: 0.0700 - val_loss: 16.6955 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.3654 - accuracy: 0.0817\n",
            "Epoch 32: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 517ms/step - loss: 4.3654 - accuracy: 0.0817 - val_loss: 16.8734 - val_accuracy: 0.0025\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.2299 - accuracy: 0.0848\n",
            "Epoch 33: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 691ms/step - loss: 4.2299 - accuracy: 0.0848 - val_loss: 16.7881 - val_accuracy: 0.0025\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.1662 - accuracy: 0.1020\n",
            "Epoch 34: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 517ms/step - loss: 4.1662 - accuracy: 0.1020 - val_loss: 17.1151 - val_accuracy: 0.0049\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 4.0043 - accuracy: 0.1136\n",
            "Epoch 35: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 696ms/step - loss: 4.0043 - accuracy: 0.1136 - val_loss: 17.3299 - val_accuracy: 0.0025\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.9139 - accuracy: 0.1198\n",
            "Epoch 36: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 517ms/step - loss: 3.9139 - accuracy: 0.1198 - val_loss: 17.7757 - val_accuracy: 0.0049\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.8107 - accuracy: 0.1370\n",
            "Epoch 37: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 690ms/step - loss: 3.8107 - accuracy: 0.1370 - val_loss: 17.8198 - val_accuracy: 0.0025\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.6714 - accuracy: 0.1591\n",
            "Epoch 38: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 516ms/step - loss: 3.6714 - accuracy: 0.1591 - val_loss: 17.9957 - val_accuracy: 0.0025\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.5960 - accuracy: 0.1609\n",
            "Epoch 39: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 737ms/step - loss: 3.5960 - accuracy: 0.1609 - val_loss: 18.0950 - val_accuracy: 0.0049\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.4851 - accuracy: 0.1763\n",
            "Epoch 40: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 750ms/step - loss: 3.4851 - accuracy: 0.1763 - val_loss: 18.2598 - val_accuracy: 0.0049\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3761 - accuracy: 0.1904\n",
            "Epoch 41: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 662ms/step - loss: 3.3761 - accuracy: 0.1904 - val_loss: 18.4915 - val_accuracy: 0.0049\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.3075 - accuracy: 0.2015\n",
            "Epoch 42: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 517ms/step - loss: 3.3075 - accuracy: 0.2015 - val_loss: 18.9187 - val_accuracy: 0.0074\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.1591 - accuracy: 0.2181\n",
            "Epoch 43: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 664ms/step - loss: 3.1591 - accuracy: 0.2181 - val_loss: 18.9876 - val_accuracy: 0.0025\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 3.0807 - accuracy: 0.2303\n",
            "Epoch 44: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 516ms/step - loss: 3.0807 - accuracy: 0.2303 - val_loss: 19.0594 - val_accuracy: 0.0025\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.9652 - accuracy: 0.2543\n",
            "Epoch 45: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 671ms/step - loss: 2.9652 - accuracy: 0.2543 - val_loss: 19.4117 - val_accuracy: 0.0049\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.8947 - accuracy: 0.2660\n",
            "Epoch 46: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 522ms/step - loss: 2.8947 - accuracy: 0.2660 - val_loss: 19.5120 - val_accuracy: 0.0074\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7985 - accuracy: 0.2813\n",
            "Epoch 47: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 667ms/step - loss: 2.7985 - accuracy: 0.2813 - val_loss: 19.9324 - val_accuracy: 0.0049\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.7588 - accuracy: 0.2918\n",
            "Epoch 48: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 518ms/step - loss: 2.7588 - accuracy: 0.2918 - val_loss: 20.1601 - val_accuracy: 0.0049\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.6158 - accuracy: 0.3077\n",
            "Epoch 49: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 9s 692ms/step - loss: 2.6158 - accuracy: 0.3077 - val_loss: 20.1303 - val_accuracy: 0.0049\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - ETA: 0s - loss: 2.5730 - accuracy: 0.3292\n",
            "Epoch 50: val_loss did not improve from 8.51159\n",
            "13/13 [==============================] - 7s 516ms/step - loss: 2.5730 - accuracy: 0.3292 - val_loss: 20.4814 - val_accuracy: 0.0049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Best Model"
      ],
      "metadata": {
        "id": "ZW8Qn8-T7vKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('best_model_lstm1.h5')"
      ],
      "metadata": {
        "id": "ltnjLjqfmYIo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Music Predictions"
      ],
      "metadata": {
        "id": "c1mdFZUX7zC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_music(model, start_sequence, length=50):\n",
        "    prediction_output = []\n",
        "\n",
        "    # Ensure start_sequence is correctly formatted\n",
        "    start_sequence_formatted = np.array([note_to_int[note] for note in start_sequence])\n",
        "\n",
        "    for note_index in range(length):\n",
        "        prediction_input = np.reshape(start_sequence_formatted, (1, len(start_sequence_formatted), 1))\n",
        "        prob = model.predict(prediction_input)[0]\n",
        "        index = np.random.choice(range(len(prob)), p=prob)\n",
        "        predicted_note = x_int_to_note[index]  # Use the inverse mapping\n",
        "        prediction_output.append(predicted_note)\n",
        "\n",
        "        # Update start_sequence_formatted for the next prediction\n",
        "        start_sequence_formatted = np.append(start_sequence_formatted, [index])[1:]\n",
        "\n",
        "    return prediction_output\n",
        "\n",
        "# Create the inverse mapping from integers back to note tuples\n",
        "x_int_to_note = dict((number, note) for note, number in note_to_int.items())"
      ],
      "metadata": {
        "id": "wF87tLOZmYGg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Back to MIDI"
      ],
      "metadata": {
        "id": "NqQCCHlE75Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import stream, instrument, note, chord, midi\n",
        "\n",
        "def midi_number_to_note_name(midi_number):\n",
        "    # Converts a MIDI note number to a note name\n",
        "    return midi.translate.pitchToNoteName(midi_number)\n",
        "\n",
        "def convert_to_midi(prediction_output):\n",
        "    midi_stream = stream.Stream()\n",
        "    midi_stream.append(instrument.Violin())\n",
        "\n",
        "    offset = 0\n",
        "    for note_info in prediction_output:\n",
        "        note_name = note_info[0]\n",
        "\n",
        "        # Convert MIDI note numbers to note names\n",
        "        if note_name.isdigit():\n",
        "            note_name = midi_number_to_note_name(int(note_name))\n",
        "\n",
        "        # Create note or rest\n",
        "        if note_name != 'rest':\n",
        "            new_note = note.Note(note_name)\n",
        "        else:\n",
        "            new_note = note.Rest()\n",
        "\n",
        "        new_note.duration.quarterLength = note_info[1]\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Violin()\n",
        "        midi_stream.append(new_note)\n",
        "        offset += note_info[2]\n",
        "\n",
        "    midi_stream.write('midi', fp='lstm_music1.mid')"
      ],
      "metadata": {
        "id": "8JzJHhffgz5G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select a starting sequence from x_val\n",
        "random_index = np.random.randint(0, len(x_val))\n",
        "start_sequence = x_val[random_index]\n",
        "\n",
        "# Since start_sequence is currently encoded as integers, decode it back to note information\n",
        "start_sequence_decoded = [x_int_to_note[note] for note in start_sequence.flatten()]\n",
        "\n",
        "# Generate music based on the starting sequence\n",
        "prediction_output = generate_music(model, start_sequence_decoded)\n",
        "convert_to_midi(prediction_output)\n"
      ],
      "metadata": {
        "id": "p5c3cXUF_eiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}