{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5yzJLQhSC9S"
      },
      "source": [
        "# The AI Violinist\n",
        "### Crafting Notes Beyond Human"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXoSG1vCyWXF"
      },
      "source": [
        "<div style=\"text-align: left;\" style=\"border: 2px solid black;\">\n",
        "    <img src=\"notebooks/AI_Violinist.png\" alt=\"AI_Violinist\" width=\"600\" height=\"500\">\n",
        "</div>\n",
        "<div align=\"left\">\n",
        "    <font size=\"1\">Image by DALL-E</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This project represents a groundbreaking exploration into the realm of music generation using advanced machine learning techniques. Leveraging the rich dataset of violin audio files and cutting-edge models, this endeavor aims to innovate the way we create and perceive music."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business Objective\n",
        "The core objective of this project is to **generate violin music autonomously using machine learning models**. This aligns with broader interests in automating and enhancing creative processes through AI.\n",
        "\n",
        "## Data Overview\n",
        "- **Dataset**: The project utilizes a collection of 1,500 violin audio file previews, each 30 seconds in length. Additionally, 150 MIDI files and 688 spectrogram files were generated from the dataset.\n",
        "\n",
        "- **Source**: These audio previews were meticulously sourced using the Spotify API, ensuring a diverse and high-quality dataset.\n",
        "\n",
        "- [Link to Data Folders](https://drive.google.com/drive/u/0/folders/16jsUFzij_pxj7f-OBSa0ioWp5Ub78uOl)\n",
        "\n",
        "\n",
        "## Audio Processors Used\n",
        "1. **Pitch Detection with CREPE**: A deep learning-based tool designed to analyze audio and accurately detect pitch. \n",
        "\n",
        "2. **Rhythm & Tempo Analysis**: Advanced algorithms that dissect audio to pinpoint rhythmic patterns and tempo variations.\n",
        "\n",
        "\n",
        "## Models Used\n",
        "1. **WaveNet**: A deep neural network for generating raw audio waveforms, renowned for its ability to produce coherent and realistic sounds.\n",
        "\n",
        "2. **LSTM (Long Short-Term Memory)**: A type of recurrent neural network (RNN) used to understand the sequence and temporal dependencies within the audio data.\n",
        "\n",
        "3. **Jukebox (Pre-Trained)**: Leveraging OpenAI's Jukebox, a pre-trained model, as a foundation to further fine-tune and generate complex music compositions.\n",
        "\n",
        "\n",
        "## Challenges & Limitations\n",
        "- Limited computational resources!!!\n",
        "\n",
        "- Multiple complex models for audio converting, predicting, and generating.\n",
        "\n",
        "- It's important to learn from failure. Checkout the 'Failed_Models_Spectrograms.ipynb' for comprehensive trial and error documentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFWItN-WvtWB"
      },
      "source": [
        "# Notebook Directory\n",
        "``` bash\n",
        "├── AI_Violinist_Intro.ipynb                <- Data capture/project overview\n",
        "├── Model_1_WaveNet.ipynb                   <- Baseline/WaveNet Models\n",
        "├── Model_2_LSTM.ipynb                      <- First LSTM Model\n",
        "├── Model_3__Complex_LSTM.ipynb             <- Second LSTM Model\n",
        "├── Visual_Analysis_Model_Comparison.ipynb  <- Model Evaluation\n",
        "├── Pretrained_Model_Jukebox.ipynb          <- Generating Final Music\n",
        "└── Failed_Models_Spectrograms.ipynb        <- Failed attempts\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "        <img src=\"notebooks/Computerized_Violin.png\" alt=\"Computerized_Violin\" width=\"700\" height=\"200\">\n",
        "    </div>\n",
        "</div>\n",
        "<div align=\"center\">\n",
        "    <font size=\"1\">Image by DALL-E</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQMFIDzuzlF6"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pJtYWs-zkhC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "from pydub import AudioSegment\n",
        "import torch\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw8YoXm30Pxb"
      },
      "source": [
        "## Collecting Data\n",
        "### Spotify API Access and Track Downloads\n",
        "\n",
        "First, I'll collect my data by automating the process of accessing the Spotify API to search for violin tracks and download their previews. It includes functions for obtaining an access token, searching for tracks, and downloading the track previews along with their metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKFQ1SoRy_gq"
      },
      "outputs": [],
      "source": [
        "# Function to obtain an access token from Spotify\n",
        "def get_spotify_access_token(client_id, client_secret):\n",
        "    # Making a POST request to Spotify Accounts for token\n",
        "    auth_response = requests.post('https://accounts.spotify.com/api/token', {\n",
        "        'grant_type': 'client_credentials',\n",
        "        'client_id': client_id,\n",
        "        'client_secret': client_secret,\n",
        "    })\n",
        "    # Returning the access token\n",
        "    return auth_response.json().get('access_token')\n",
        "\n",
        "# Function to search for violin tracks on Spotify\n",
        "def search_violin_tracks(access_token, query, offset=0, limit=50):\n",
        "    # Headers with authorization token\n",
        "    headers = {'Authorization': f'Bearer {access_token}'}\n",
        "    # Constructing the search URL\n",
        "    search_url = f'https://api.spotify.com/v1/search?q={query}&type=track&market=US&limit={limit}&offset={offset}'\n",
        "    # Making a GET request to search tracks\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    # Returning the search result as JSON\n",
        "    return response.json()\n",
        "\n",
        "# Function to download track previews and save metadata\n",
        "def download_track_previews(tracks, download_folder, metadata_file):\n",
        "    with open(metadata_file, 'a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Iterating through each track item\n",
        "        for track in tracks['tracks']['items']:\n",
        "            preview_url = track['preview_url']\n",
        "            # Downloading only if preview URL is available\n",
        "            if preview_url:\n",
        "                # Extracting track information\n",
        "                track_id = track['id']\n",
        "                track_name = track['name']\n",
        "                artist_name = track['artists'][0]['name']\n",
        "                album_name = track['album']['name']\n",
        "                file_name = os.path.join(download_folder, f\"{track_id}.mp3\")\n",
        "                # Writing metadata to CSV file\n",
        "                writer.writerow([track_id, track_name, artist_name, album_name, preview_url])\n",
        "                # Downloading the preview\n",
        "                download_preview(preview_url, file_name)\n",
        "                print(f\"Downloaded preview: {file_name}\")\n",
        "\n",
        "# Function to download a track preview from a URL\n",
        "def download_preview(url, file_name):\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        with open(file_name, 'wb') as f:\n",
        "            # Writing the content in chunks to a file\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "# Main function to orchestrate the downloading process\n",
        "def main():\n",
        "    # Spotify API credentials (hidden for security)\n",
        "    client_id = 'hidden_for_security'\n",
        "    client_secret = 'hidden_for_security'\n",
        "    # Setting up directories and file names\n",
        "    download_folder = 'violin_track_previews'\n",
        "    metadata_file = 'violin_track_metadata.csv'\n",
        "    # Defining search queries\n",
        "    search_queries = ['violin instrumental', 'strings instrumental']\n",
        "\n",
        "    # Getting access token\n",
        "    token = get_spotify_access_token(client_id, client_secret)\n",
        "\n",
        "    # Creating download directory if it doesn't exist\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    # Creating or resetting metadata file\n",
        "    if not os.path.exists(metadata_file):\n",
        "        with open(metadata_file, 'w', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(['Track ID', 'Track Name', 'Artist Name', 'Album Name', 'Preview URL'])\n",
        "\n",
        "    # Looping through each query to search and download tracks\n",
        "    for query in search_queries:\n",
        "        offset = 0\n",
        "        while True:\n",
        "            try:\n",
        "                # Searching tracks\n",
        "                tracks = search_violin_tracks(token, query, offset)\n",
        "                # Break if no items found\n",
        "                if not tracks['tracks']['items']:\n",
        "                    break\n",
        "                # Downloading previews and metadata\n",
        "                download_track_previews(tracks, download_folder, metadata_file)\n",
        "                # Incrementing offset for pagination\n",
        "                offset += 50\n",
        "                # Adding sleep to respect rate limits\n",
        "                time.sleep(1)\n",
        "            except KeyError:\n",
        "                break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b8M3DcK7Z2W"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpMbiI1Xz-Kf"
      },
      "source": [
        "### MP3 to WAV Conversion\n",
        "\n",
        "In order for the models to process my data, I'll need to take some preprocessing steps.\n",
        "\n",
        "First, I'll convert the MP3 audio files to WAV format. I'll set a target sample rate, as required by some pre-trained models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6dwzZ5z8sU9"
      },
      "outputs": [],
      "source": [
        "input_folder = 'Violin_Comp_Data/MyDrive/Violin_Comp_Data/violin_track_previews'\n",
        "output_folder = 'Violin_Comp_Data/MyDrive/Violin_Comp_Data/converted_music_files'\n",
        "target_sample_rate = 44100\n",
        "\n",
        "# Function for converting mp3 files to .wav\n",
        "def convert_audio_to_wav(input_path, output_path, target_sample_rate=44100):\n",
        "    # Load the MP3 file\n",
        "    audio = AudioSegment.from_file(input_path, format=\"mp3\")\n",
        "\n",
        "    # Convert to the target sample rate\n",
        "    audio = audio.set_frame_rate(target_sample_rate)\n",
        "\n",
        "    # Export the converted file\n",
        "    audio.export(output_path, format=\"wav\")\n",
        "\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith('.mp3'):\n",
        "        input_path = os.path.join(input_folder, file_name)\n",
        "        output_path = os.path.join(output_folder, file_name.replace('.mp3', '.wav'))\n",
        "        convert_audio_to_wav(input_path, output_path, target_sample_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRUaGv2u0DZh"
      },
      "source": [
        "### Loading Audio Files into Tensors\n",
        "\n",
        "This function loads audio files and converts them into PyTorch tensors for further processing. Each audio file is normalized and converted to a mono-channel tensor for efficiency and focusing on relevant features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5wMYmpZa7Yj"
      },
      "outputs": [],
      "source": [
        "def load_audio_file(file_path, target_sample_rate=44100):\n",
        "    # Load an audio file using pydub\n",
        "    audio = AudioSegment.from_file(file_path).set_frame_rate(target_sample_rate).set_channels(1)\n",
        "\n",
        "    # Convert to samples\n",
        "    samples = torch.tensor(audio.get_array_of_samples()).float()\n",
        "\n",
        "    # Normalize\n",
        "    samples = samples / (2**15)\n",
        "\n",
        "    return samples.view(1, -1)\n",
        "\n",
        "def load_dataset(directory):\n",
        "    dataset = []\n",
        "    for file_name in os.listdir(directory):\n",
        "        if file_name.endswith('.wav'):\n",
        "            file_path = os.path.join(directory, file_name)\n",
        "            audio_tensor = load_audio_file(file_path)\n",
        "            dataset.append(audio_tensor)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "directory = '/content/gdrive/MyDrive/Violin_Comp_Data/converted_music_files'\n",
        "dataset = load_dataset(directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm2OzPpQ0ViO"
      },
      "source": [
        "### Converting Audio to Spectrogram Images\n",
        "\n",
        "This function loads audio files and converts them into spectrogram images. It uses `librosa` to create a Short-Time Fourier Transform (STFT) spectrogram and saves them as PNG images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3hBIUbNyjC3"
      },
      "outputs": [],
      "source": [
        "def audio_to_spectrogram(file_path, save_path, file_name, sr=22050, n_fft=2048, hop_length=512):\n",
        "    # Load audio file\n",
        "    y, sr = librosa.load(file_path, sr=sr)\n",
        "\n",
        "    # Create a spectrogram\n",
        "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
        "    Y = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(Y, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Spectrogram')\n",
        "\n",
        "    # Save the spectrogram as an image\n",
        "    plt.savefig(os.path.join(save_path, f\"{file_name}.png\"))\n",
        "    plt.close()\n",
        "\n",
        "# Directory containing your audio files\n",
        "audio_dir = '/content/gdrive/MyDrive/Violin_Comp_Data/converted_music_files'\n",
        "\n",
        "# Directory to save the spectrograms\n",
        "spectrogram_dir = '/content/gdrive/MyDrive/Violin_Comp_Data/spectrograms'\n",
        "if not os.path.exists(spectrogram_dir):\n",
        "    os.makedirs(spectrogram_dir)\n",
        "\n",
        "# Convert all files in the directory\n",
        "for file in os.listdir(audio_dir):\n",
        "    if file.endswith('.wav'):\n",
        "        file_path = os.path.join(audio_dir, file)\n",
        "        file_name = os.path.splitext(file)[0]\n",
        "        audio_to_spectrogram(file_path, spectrogram_dir, file_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbnjpL9y0gpY"
      },
      "source": [
        "Due to high RAM requirements, I was only able to create 688 spectrograms out of approx. 1500 music files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2YG_NV4-BiQ"
      },
      "source": [
        "### Sampling Audio Files\n",
        "\n",
        "Now I'll randomly select a sample of audio files (10% of the total) for testing models in order to save computational resources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MGhBHIm95bz"
      },
      "outputs": [],
      "source": [
        "directory_path = '/content/gdrive/MyDrive/Violin_Comp_Data/converted_music_files'\n",
        "new_directory_path = '/content/gdrive/MyDrive/Violin_Comp_Data/sample_audio_files'\n",
        "\n",
        "# Create the new directory if it doesn't exist\n",
        "if not os.path.exists(new_directory_path):\n",
        "    os.makedirs(new_directory_path)\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "all_files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
        "\n",
        "# Filter to include only .wav files\n",
        "audio_files = [f for f in all_files if f.lower().endswith('.wav')]\n",
        "\n",
        "# Calculate 10% sample size\n",
        "sample_size = int(len(audio_files) * 0.1)\n",
        "\n",
        "# Randomly select the files\n",
        "sampled_files = random.sample(audio_files, sample_size)\n",
        "\n",
        "# Copy the sampled files to the new directory\n",
        "for file in sampled_files:\n",
        "    source = os.path.join(directory_path, file)\n",
        "    destination = os.path.join(new_directory_path, file)\n",
        "    shutil.copy2(source, destination)\n",
        "\n",
        "print(f\"Total files: {len(audio_files)}\")\n",
        "print(f\"Sampled files ({sample_size}) have been copied to {new_directory_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "        <img src=\"images/Computerized_Violin.png\" alt=\"Computerized_Violin\" width=\"700\" height=\"200\">\n",
        "    </div>\n",
        "</div>\n",
        "<div align=\"center\">\n",
        "    <font size=\"1\">Image by DALL-E</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "This project demonstrates the use of advanced machine learning models to generate violin music, marking a significant step in AI-generated art. Despite computational limitations, the models were able to produce coherent and aesthetically pleasing music."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "- **Enhance Computational Resources**: To overcome the limitation of processing power, future work may involve leveraging more robust computational infrastructure or cloud-based solutions.\n",
        "\n",
        "- **Refining MIDI Conversion Techniques**: Continuous improvement and fine-tuning of the models to enhance the quality and diversity of the generated music starts with high quality audio. \n",
        "\n",
        "- **Exploring Diverse Instruments**: Expanding the project scope to include other instruments and genres, exploring the full spectrum of musical creativity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sources\n",
        "- Spotify API\n",
        "\n",
        "- [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/)\n",
        "\n",
        "- [OpenAI's Jukebox](https://openai.com/research/jukebox)\n",
        "\n",
        "- [One Click Jukebox with Autosave v2](https://colab.research.google.com/github/openai/jukebox/blob/master/jukebox/Interacting_with_Jukebox.ipynb)\n",
        "\n",
        "- All images created by DALL-E\n",
        "\n",
        "- This notebook was, of course, developed using knowledge from ChatGPT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proceed to 'Model_1_WaveNet.ipynb'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
